\section*{Synthesizing Measures of State Preference}

The approach that we introduce here to measuring state preferences starts by assuming that both UN voting and alliance relationships are sources of information on how states relate to one another in the international stage. By accounting for the multiple layers upon which states interact with one another we can synthesize a better measure of state preferences than if we relied on any one measure alone. The idea of using multiple metrics to get a better handle on preferences is not new, in fact, Signorino and Ritter suggested it in introducing S scores, which were designed to allow for aggregation of similarity on multiple dimensions (such as alliances and UN voting). The downside of this extant approach, however, is that it does not account for structural patterns that we often see in relational data. 

Relational data is composed of observations between pairs of actors, or dyads. For both alliance relationships and UN voting, we are able to observe how the actors in the international system  interacted with one another across time. This system of interactions taken in its totality defines a network, and within these types of structures a bevy of research has shown that we need methods that go beyond assuming that interactions are taking place between just two actors in a vacuum \citep{wasserman:faust:1994,snijders:nowicki:1997}. As such we reformulate the problem of determining state preferences in terms of network analysis. The goal of our approach is summarized in Figure~\ref{fig:tensViz}. In the top row, we represent UN voting and alliance patterns at time $t$ in a pair of adjacency matrices that form a multiplex.\footnote{The approach that we describe here can be generalized to a multiplex with more than two dimensions.} This multiplex represents the relations between states across two dimensions, and our goal is to extract a lower dimensional representation that accounts for higher order network patterns such as stochastic equivalence. The end result then will be a single $n \times n$ matrix, where $n$ represents the number of actors, in which the cross-sections denote our predictions for the strength of relations between two countries.

% needs to be modified
\begin{figure}[ht]
	\centering
	% \includegraphics[width=.8\textwidth]{carbonStrat.png}
	\resizebox{.5\textwidth}{!}{\input{dimRedStrat.tex}}
	\caption{Tensor representation of longitudinal dyadic, representational measures. The green and blue colors represent different relational measures and darker shading indicates later time periods. Specifically, we show a tensor with dimensions of $4 \times 4 \times 2 \times 3$, where 4 represents the number of actors, 2 the number of relational measures, and 3 the number of time points.}
	\label{fig:tensViz}
\end{figure}

We generate these predictions through a matrix decomposition technique that estimates a latent Gaussian score for each country pair. We will show that by combining different measures of state preferences, and better accounting for network dependencies through our approach, we are able to generate a measure for preference that: maintains the insights of both UN voting scores and S-scores; and which can yield new insights, in particular, when it comes to predicting and explaining interstate conflict.

\subsection*{Latent Factor Model}

A number of techniques have been developed in recent years to estimate low-dimensional representations of network structures.\footnote{For a literature review of these approaches see \citet{goldenberg:etal:2010}.} For many of these approaches the goal is to account for higher order dependence pattern such as stochastic equivalence. Stochastic equivalence refers to the idea that there are communities of nodes in a network, and actors within a community act similarly towards those in other communities. Thus the community membership of an actor provides us with information on how that actor will act towards others in the network. Put more concretely, a pair of actors $ij$ are stochastically equivalent if the probability of $i$ relating to, and being related to, by every other actor is the same as the probability for $j$ \citep{anderson:etal:1992}. An additional dependence pattern that often manifests in networks is homophily -- the tendency of actors to form transitive links. The presence of homophily in a network implies that actors may cluster together because they share some latent attribute. In the context of clustering in alliance relationships, we are likely to find that states like the United States, United Kingdom, and Germany may cluster together because they share some latent state level attribute. Ignoring these patterns when generating a measure of state preferences is likely to paint an incomplete picture of the preferences that states share with one another.

We account for higher order dependence patterns using a latent factor model (LFM) that allows us to capture both concepts discussed above: the tendency of actors to assort themselves into groups and to form transitive links \citep{hoff:2007,minhas:etal:2016:arxiv}. Using the LFM ensures that similarity in preferences are likely to be transitive, for example, if the US has similar preferences to the UK, and the UK to France, the US's preferences should be relatively close to France's. The most useful feature of the LFM for our purpose is that it provides a visual interpretation of those interdependencies by inferring actor positions in a k-dimensional latent vector space. Actors that have vectors pointing in similar directions are more likely to have similar state preferences based on their alliances and UN voting records. The angle between the vectors for actors $i$ and $j$ provides an estimate of how similar the state preferences of $i$ are to $j$. 

To generate this measure we begin by constructing $T$ $n \times n \times p$ arrays, where $T$ represents the number of periods, $n$ represents the number of actors,\footnote{The number of actors can vary by period.} and $p$ the number of observed variables used to synthesize a measure of state preference. In this case, both alliance relationships and UN voting scores are undirected measures, meaning that $y_{ij} = y_{ji} \; \forall \; p \text{ and } t$.\footnote{The approach we describe below has already been generalized to the case where $y_{ij} \neq y_{ji}$.} In order to obtain a lower-dimension relational measure of state preferences, we use the LFM separately for each time point: 

\begin{align*}
	Y &= f(\theta)\\
	\theta &= \beta^{\top} X + Z \\
	Z &= M + E  \\
	M &= U \Lambda U^{\top}\text{, where } \\
	&\qquad u_{i} \in \rm I\!R^{k} \text{ and } \\ 
	&\qquad \Lambda \text{ is a } k \times k \text{ diagonal matrix}
\end{align*}

where $f(.)$ is a general link function corresponding to the distribution of $Y$ and $\beta^{\top}\mathbf{X}$ is the standard regression term for dyadic and nodal fixed effects. In this application, for the sake of parsimony we abstain from using fixed effects. However, if one was interested in estimating a measure of preference that parsed out the effect of geographic distance between $i$ and $j$, for example, than this could be accomplished within the context of this framework by simply including that as a covariate in the $X$ design array. $Z$ represents any additional patterns in data unrelated to the specified dyadic and nodal fixed effects. To incorporate multiple measures of similarity into a single ideal point estimation, we treat each different slice of data as arising from a common distribution. In this way, each additional observed relationship between actors that we add serves to provide additional information to the model that can be used to estimate a latent measure of state preference. 

The key part of this model lies in the decomposition of $Z$. \citet{hoff:2009} notes that we can write $Z = M + E$ such that the matrix $E$ represents noise, and $M$ is systematic effects. By matrix theory, we can factorize $M$ into the product of two simpler matrices: $M = U \Lambda U^{\top}$, where $u_{i} \in \rm I\!R^{k}$ is a latent vector associated to node $i$ and $\Lambda$ is a $k \times k$ diagonal matrix. Thus under this framework a vector of latent characteristics are estimated for each actor, $u_{i} = \{u_{i,1}, \ldots, u_{i,k}\}$. Similarity in the latent factors between two actors, $u_{i} \approx u_{j}$, corresponds to how stochastically equivalent they are and the diagonal entries in $\Lambda$, $\lambda_{k} > 0 \text{ or } \lambda_{k} < 0$, determine the level of homophily (or antihomophily) in the network \citep{minhas:etal:2016:arxiv}. Within this framework, the LFM can represent both positive or negative homophily in varying degrees and stochastially equivalent actors may or may not share strong relationships with others in their ``community''.

Inference of the latent vectors for each actor takes place within the context of a Markov Chain Monte Carlo (MCMC) procedure that enables us to construct approximate samples from the posterior distributions of the latent variables. For the latent factor model, a diffuse normal prior is placed on $\Lambda$ and the prior distribution on $U$ is taken to be a uniform distribution. The MCMC proceeds by sampling the parameters from their full conditional distributions for each $k$: sample $u_{i}, \ldots, u_{n}$ from a multivariate normal distribution and then sample $\Lambda$ from its multivariate normal distribution. A Bayesian procedure to determine the eigenvalue decomposition is available in the \pkg{amen} $\sf{R}$ package \citep{amenpkg}. 

The key output from the LFM for our purpose here is $U \Lambda U^{\top}$. This multiplicative effect not only helps to account for homophily and stochastic equivalence, it also places each state in a latent factor space. What is key to understand about this latent space is that it is non-euclidian. Rather than have states behave similar to the states which are close to them, this latent space is a two dimensional representation of a hypersphere, and thus states are apt to behave similarly to the states that are placed in the same direction on said sphere. Thus, if two states vectors (from the center of the space) are in the same direction, they are apt to send and receive both alliances and co-voting to similar targets. The way we measure this similarity in dimension is by looking at the absolute distance of the angles created by each states position and the center of the latent space. 

% https://books.google.com/books?id=Bb0UBQAAQBAJ&pg=PA101&lpg=PA101&dq=latent+factor,+cosine+angle&source=bl&ots=rGdBVz7jJV&sig=pD8XM9e_nVJhga89Bnn7jw7AQ5w&hl=en&sa=X&ved=0ahUKEwics8ruqN3UAhUFwmMKHUf8Av8Q6AEINTAD#v=onepage&q=latent%20factor%2C%20cosine%20angle&f=false
% To define diversity let us revisit the latent factor representation of users and products obtained through matrix factorization: each user and product is represented by a vector of latent factors, where these latent factors are abstract or real=life characteristics. This means that a product vector's direction within the latent factor high-dimensional space indicates which characteristics this product has and which it does not have. Hence two products can be compared by comparing the direction to which their respective factor vectors point. In this sense, the straightforward choice for a comparison metric between products is the cosine of the angle formed by these products. This metric is well known as the cosine similarity/distance, defined as $cosSim_{a,b} = \frac{p_{a} \cdot p_{b}}{||p_{a}|| \cdot ||p_{b}||}$. Here $p_{a}$ and $p_{b}$ denote products $a$ and $b$ factor vectors. Notice that cosine similarity ranges from -1 to 1. Using the cosine similarity metric our intuition is that a set of 2 products will be more diversified if the cosine similarity between its product is negative or close to zero. Figure 1 illustrates the intuition behind cosine diversity. Accounting for vertex directions by measuring the diversity in terms of the sums of the vertex angles avoids the curse of high-dimensionality problem and is more consistent with what we consider to be diversity. 


% https://cambridgespark.com/content/tutorials/implementing-your-own-recommender-systems-in-Python/index.html

% A distance metric commonly used in recommender systems is cosine similarity, where the ratings are seen as vectors in nn-dimensional space and the similarity is calculated based on the angle between these vectors. Cosine similiarity for users aa and mm can be calculated using the formula below, where you take dot product of the user vector ukuk and the user vector uaua and divide it by multiplication of the Euclidean lengths of the vectors.

% scosu(uk,ua)=uk⋅ua‖uk‖‖ua‖=∑xk,mxa,m∑x2k,m∑x2a,m‾‾‾‾‾‾‾‾‾‾‾‾‾√
% sucos(uk,ua)=uk⋅ua‖uk‖‖ua‖=∑xk,mxa,m∑xk,m2∑xa,m2

% To calculate similarity between items mm and bb you use the formula:

% scosu(im,ib)=im⋅ib‖im‖‖ib‖=∑xa,mxa,b∑x2a,m∑x2a,b‾‾‾‾‾‾‾‾‾‾‾‾√