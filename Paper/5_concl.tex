\section*{Conclusion}

We use a network methodology to create a new measure of state preferences using both UN Voting data and alliance data. This measure of state preferences demonstrates face plausibility comparable or superior to existing measures when it comes to capturing the dynamics of a number of notable dyadic relationships. We then attempt to use this measure of state preferences in a predictive model of interstate disputes. In doing so, we find that the measure of preferences has the expected effect (states with similar preferences are less likely to be involved in disputes) and inclusion of our measure leads to the measure of joint democracy becoming indistinguishable from $0$. Most importantly, a model of interstate conflict that includes our measure of preferences decisively outperforms models that include both of the most prominent existing measures of preferences.


While this measure of state preferences has yielded leverage in predicting conflict, it should also be useful in answering a number of other questions. One possible use would be to look at the measure of state preferences as an outcome variable, rather than a predictor. We could here look at how preferences change in tandem with leadership change -- can we find evidence, for example, that the election of Donald Trump moved the United States' foreign policy preferences away from the major Western European states and towards Russia's? We could also see how well this measure of state preferences predicts more collaborative behavior -- treaty membership or trade for example.

Finally, this particular method allows us to control for confounding fixed effects. A closer examination of the relationship between democracy, preferences, and conflict could create a measure of the component of state preferences not explained by democracy.\footnote{We look at the entire measure of state preferences because our primary goal here is not to examine this relationship, but to create the most accurate measure of preferences possible.}  Similarly, the underlying methodology could be usefully applied to other questions. For example, it could be used to estimate the alignments of elites in non-democratic states  or even as a way of combining a number of related variables on development or democracy. 

Ours is not the first paper to use network analysis to attempt to measure a theoretically important but difficult to observe phenomenon. For example, \citet{moody:white:2003} measured social cohesion by looking at the minimum number of paths connecting each actor in a group (and applied to high school friendship networks and among American businesses. A similar approach, by \citet{beardsley:etal:2018} generates a measure of hierarchy by looking at a network of arms transfers and first finding the clusters in each group,  then how central an actor is within a given cluster, they go on to use this measure of hierarchy in a downstream model to explain interstate conflict, and similarly \citet{cranmer:etal:2015} use a measure of multiplex modularity in the network of alliances, trade, and international organization membership to measure ``Kantian fractionalization"--the extent to which the international system is fragmented between liberal and illiberal states--which predicts the aggregate level of violence. Where we differ from this work, however, is that while previous attempts at measurement using networks have relied on descriptive statistics of observed networks, we use a Latent Factor approach which assumes that the network we study is observed with error from the true data-generating process.  In cases where the network is observed accurately, and measurement directly flows from this network, our approach is unnecessary and selection of appropriate descriptive statistics should suffice for measurement. However, in many cases, especially in the social sciences, we either observe the true network with error, or we select a network as a proxy for the true process we want to measure. 

In addition to helping us to understand state preferences, this sort of technique could help in measuring phenomenon like social cohesion and hierarchy, or spatial contagion. If one wanted to use a latent network approach to measure social cohesion, one could potentially do this with a Latent Class Model like in \citet{airoldi:etal:2006}. Using some measure of social interaction, this model would give the probability that each member is in a particular clique or subgroup in society. We could then look at how many members of society have probability of membership in multiple groups above a certain threshold to see how many individuals bridge different groups, contributing to social cohesion in the way that \citet{moody:white:2003} measured it. In understanding how phenomenon -- violence, diseases, new technology to name a few examples -- diffuse, many scholars rely on spatial lag models, which require the scholar to specify a spatial weights matrix that indicates how likely a phenomenon is to move from one area to another. Of course, we can never know the true adjacency matrix, and so scholars use a proxy, most often some form of geographic distance. We can (and in the case of political violence have) improved the predictive performance of spatial models by inferring a weights matrix using a latent network approach based on how the phenomenon has diffused in the past. 

If a latent network approach is needed, the specific type used should depend on the problem.\footnote{For more information on different types of latent networks, see \citet{minhas:etal:2018} or \citet{goldenberg:etal:2010}. If your beliefs about the true data-generating process you wish to measure are that it is about membership in disjoint groups, and you have a strong prior on the number of extant groups, a Latent Class Model (see \citet{airoldi:etal:2008}) will  clearly measure the probability of membership in these groups, and as \citet{goldenberg:etal:2010} note, it is the easiest model to interpret. However, many phenomena cannot meet the assumption of the Latent Class Model. The Latent Space Model popularized by \citet{handcock:etal:2008} is another model where results are easy to interpret, and requires less assumptions and priors about the data-generating process, but if you wish to measure something related to homophily or stochastic equivalence, this model will not capture those.  As \citet{goldenberg:etal:2010}[p.179] note, the latent factor model (which we use) ``can capture more connectivity patterns than the latent class and the latent distance models for a given degree of model complexity...There is a price to pay, however. The eigenmodel is the least amenable to interpretation among the three models." Regardless of the model used, if you are trying to use a latent network model for measurement, and especially if you are using the measure in a downstream model, you need to be aware of and account for uncertainty. To do this, we suggest running the downstream model repeatedly with different draws from the distribution for the latent space, then combining the models using \citet{rubin:1976}'s rules to obtain an estimate of the effect of your measure that accounts for uncertainty.}

% While we would like an accurate measure of state preferences as an independent variable in our theory, measures of preferences can yield insights as a dependent variable in their own right. They could be used to see if the election of Donald Trump caused states to move their preference away from the United States, to see how the United States' preferences towards states in the Middle East changed after 9/11, or to see the impact of Russia's annexation of Crimea on their relations with their near-abroad states and the European Union.